{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf3a66-275d-44c9-84c1-8391fb7527af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "sys.path.append('../')\n",
    "sys.path.append('C:/Program Files (zk)/PythonFiles/AClassification/Heart-Sound-Diagnosis/')\n",
    "from models.classifiers import LSTM_Attn_Classifier\n",
    "from models.mobilefacenet import MobileFaceNet\n",
    "from datautils.PhysioNet2016Dataset import get_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df988276",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "train_loader, test_loader = get_loaders()\n",
    "class_loss = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534c75c-cd88-4943-9004-caf873a0d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl_model = MobileNetV2(dc=1, n_class=2, input_size=87, width_mult=1).to(device)\n",
    "cl_model = MobileFaceNet(inp_c=1, input_dim=87, latent_size=(6, 8), num_class=2, inp=1).to(device)\n",
    "x = torch.randn(16, 1, 87, 128, device=device)  # (bs, length, dim)\n",
    "label = torch.randint(low=0, high=2, size=(16,), device=device)\n",
    "tmp_pred, tmp_feat = cl_model(x, label)\n",
    "print(tmp_pred.shape, tmp_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e456e0-4049-48d5-81e3-2d11d65a04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_max = 1000\n",
    "warm_up_iter, T_max, lr_max, lr_min = 30, iter_max // 3, 5e-4, 5e-5\n",
    "# reference: https://blog.csdn.net/qq_36560894/article/details/114004799\n",
    "# 为param_groups[0] (即model.layer2) 设置学习率调整规则 - Warm up + Cosine Anneal\n",
    "lambda0 = lambda cur_iter: 0.005 * cur_iter / warm_up_iter if cur_iter < warm_up_iter else \\\n",
    "    (lr_min + 0.5 * (lr_max - lr_min) * (\n",
    "            1.0 + math.cos((cur_iter - warm_up_iter) / (T_max - warm_up_iter) * math.pi))) / 0.1\n",
    "optimizer = optim.Adam(cl_model.parameters(), lr=5e-4)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=5e-5)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda0)\n",
    "datetimestr = time.strftime(\"%Y%m%d%H%M\", time.localtime())\n",
    "setting_content = \"LSTM+DotAttn, adam LambdaLR 0 ~ 5e-4 ~ 5e-5.\"\n",
    "run_save_dir = \"./ckpt/physionet/\" + datetimestr + f'_/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bea32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = 0\n",
    "STD_acc = []\n",
    "STD_loss = []\n",
    "loss_line = []\n",
    "lr_list = []\n",
    "for epoch_id in tqdm(range(iter_max), desc=\"Train\"):\n",
    "    cl_model.train()\n",
    "    loss_list = []\n",
    "    lr_list.append(optimizer.param_groups[0]['lr'])\n",
    "    for idx, (X_mel, y_mel) in enumerate(train_loader):\n",
    "        # print(X_mel.shape, y_mel.shape)\n",
    "        # return\n",
    "        optimizer.zero_grad()\n",
    "        X_mel = X_mel.to(device)\n",
    "        if idx == 0:\n",
    "            print(X_mel.shape)\n",
    "        if X_mel.ndim == 3:\n",
    "            X_mel = X_mel.transpose(1, 2)\n",
    "            X_mel = X_mel.unsqueeze(1)\n",
    "        y_mel = y_mel.to(device)\n",
    "        print(y_mel)\n",
    "        if idx == 0:\n",
    "            print(X_mel.shape)\n",
    "        pred, _ = cl_model(x=X_mel, label=y_mel)\n",
    "        if idx == 0:\n",
    "            # torch.Size([32, 1, 87, 128]) torch.Size([32]) torch.Size([32, 5])\n",
    "            print(X_mel.shape, y_mel.shape, pred.shape)\n",
    "        loss_v = class_loss(pred, y_mel)\n",
    "        loss_v.backward()\n",
    "        loss_list.append(loss_v.item())\n",
    "        optimizer.step()\n",
    "    loss_line.append(np.array(loss_list).mean())\n",
    "    cl_model.eval()\n",
    "    with torch.no_grad():\n",
    "        acc_list = []\n",
    "        loss_list = []\n",
    "        for idx, (X_mel, y_mel) in enumerate(test_loader):\n",
    "            X_mel = X_mel.to(device)\n",
    "            if X_mel.ndim == 3:\n",
    "                X_mel = X_mel.transpose(1, 2)\n",
    "                X_mel = X_mel.unsqueeze(1)\n",
    "            y_mel = y_mel.to(device)\n",
    "            # print(X_mel.shape)\n",
    "            pred, _ = cl_model(x=X_mel, label=y_mel)\n",
    "            loss_eval = class_loss(pred, y_mel)\n",
    "            # print(y_mel.argmax(-1))\n",
    "            # print(pred.argmax(-1))\n",
    "            acc_batch = metrics.accuracy_score(y_mel.data.cpu().numpy(),\n",
    "                                               pred.argmax(-1).data.cpu().numpy())\n",
    "            acc_list.append(acc_batch)\n",
    "            loss_list.append(loss_eval.item())\n",
    "        acc_per = np.array(acc_list).mean()\n",
    "        # print(\"new acc:\", acc_per)\n",
    "        STD_acc.append(acc_per)\n",
    "        STD_loss.append(np.array(loss_list).mean())\n",
    "        if acc_per > old:\n",
    "            old = acc_per\n",
    "            print(\"new acc:\", acc_per)\n",
    "            if acc_per > 0.85:\n",
    "                print(f\"Epoch[{epoch_id}]: {acc_per}\")\n",
    "                if not os.path.exists(run_save_dir):\n",
    "                    os.makedirs(run_save_dir, exist_ok=True)\n",
    "                    with open(run_save_dir + f\"setting.txt\", 'w') as fin:\n",
    "                        # fin.write(\"MobileNetV2, adam cosine anneal 5e-4 ~ 5e-5, data augmentation, feature map max reduction.\")\n",
    "                        fin.write(setting_content)\n",
    "                torch.save(cl_model.state_dict(), run_save_dir + f\"cls_model_{epoch_id}.pt\")\n",
    "                torch.save(optimizer.state_dict(), run_save_dir + f\"optimizer_{epoch_id}.pt\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(loss_line)), loss_line, c=\"red\", label=\"train_loss\")\n",
    "plt.plot(range(len(STD_loss)), STD_loss, c=\"blue\", label=\"valid_loss\")\n",
    "plt.plot(range(len(STD_acc)), STD_acc, c=\"green\", label=\"valid_accuracy\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"metrics\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(lr_list)\n",
    "if not os.path.exists(run_save_dir):\n",
    "    os.makedirs(run_save_dir, exist_ok=True)\n",
    "    plt.savefig(run_save_dir + \"train_result.png\", format=\"png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7064c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
